{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Time_Series/item1213.csv\").iloc[:, 2:]\n",
    "data.columns = ['M0', 'qty1', 'qty2', 'qty3']\n",
    "M0, M1, M2, M3 = data['M0'], [], [], []\n",
    "M_1, M_2, M_3 = [], [], []\n",
    "# for i in range(3, len(data)):\n",
    "#     M_1.append(M0[i-1])\n",
    "#     M_2.append(M0[i-2])\n",
    "#     M_3.append(M0[i-3])\n",
    "for i in range(len(data)-3):\n",
    "    M1.append(M0[i+1])\n",
    "    M2.append(M0[i+2])\n",
    "    M3.append(M0[i+3])\n",
    "data = data.drop(['M0'], axis=1).iloc[:44, :]\n",
    "# data['M_1'], data['M_2'], data['M_3'] = M_1, M_2, M_3\n",
    "data['M0'], data['M1'], data['M2'], data['M3'] = M0, M1, M2, M3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 10, 3) (30, 4)\n"
     ]
    }
   ],
   "source": [
    "X, y = data.iloc[:, :3].values, data.iloc[:, 3:].values\n",
    "x_train = []\n",
    "y_train = []\n",
    "for i in range(10,40):\n",
    "    x_train.append(X[i-10:i, :3])\n",
    "    y_train.append(y[i,:])\n",
    "x_train,y_train = np.array(x_train),np.array(y_train)\n",
    "print(x_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.1952, 0.    , 0.    ],\n",
       "        [0.0905, 0.1132, 0.    ],\n",
       "        [0.3918, 0.0184, 0.    ],\n",
       "        [0.1174, 0.    , 0.    ],\n",
       "        [0.1132, 0.    , 0.    ],\n",
       "        [0.0481, 0.    , 0.    ],\n",
       "        [0.1047, 0.    , 0.    ],\n",
       "        [0.0679, 0.0085, 0.    ],\n",
       "        [0.0283, 0.    , 0.    ],\n",
       "        [0.0552, 0.0849, 0.    ]],\n",
       "\n",
       "       [[0.0905, 0.1132, 0.    ],\n",
       "        [0.3918, 0.0184, 0.    ],\n",
       "        [0.1174, 0.    , 0.    ],\n",
       "        [0.1132, 0.    , 0.    ],\n",
       "        [0.0481, 0.    , 0.    ],\n",
       "        [0.1047, 0.    , 0.    ],\n",
       "        [0.0679, 0.0085, 0.    ],\n",
       "        [0.0283, 0.    , 0.    ],\n",
       "        [0.0552, 0.0849, 0.    ],\n",
       "        [0.553 , 0.0099, 0.    ]],\n",
       "\n",
       "       [[0.3918, 0.0184, 0.    ],\n",
       "        [0.1174, 0.    , 0.    ],\n",
       "        [0.1132, 0.    , 0.    ],\n",
       "        [0.0481, 0.    , 0.    ],\n",
       "        [0.1047, 0.    , 0.    ],\n",
       "        [0.0679, 0.0085, 0.    ],\n",
       "        [0.0283, 0.    , 0.    ],\n",
       "        [0.0552, 0.0849, 0.    ],\n",
       "        [0.553 , 0.0099, 0.    ],\n",
       "        [0.6167, 0.4272, 0.8883]],\n",
       "\n",
       "       [[0.1174, 0.    , 0.    ],\n",
       "        [0.1132, 0.    , 0.    ],\n",
       "        [0.0481, 0.    , 0.    ],\n",
       "        [0.1047, 0.    , 0.    ],\n",
       "        [0.0679, 0.0085, 0.    ],\n",
       "        [0.0283, 0.    , 0.    ],\n",
       "        [0.0552, 0.0849, 0.    ],\n",
       "        [0.553 , 0.0099, 0.    ],\n",
       "        [0.6167, 0.4272, 0.8883],\n",
       "        [0.4583, 0.8897, 0.0198]],\n",
       "\n",
       "       [[0.1132, 0.    , 0.    ],\n",
       "        [0.0481, 0.    , 0.    ],\n",
       "        [0.1047, 0.    , 0.    ],\n",
       "        [0.0679, 0.0085, 0.    ],\n",
       "        [0.0283, 0.    , 0.    ],\n",
       "        [0.0552, 0.0849, 0.    ],\n",
       "        [0.553 , 0.0099, 0.    ],\n",
       "        [0.6167, 0.4272, 0.8883],\n",
       "        [0.4583, 0.8897, 0.0198],\n",
       "        [0.9943, 0.0198, 0.    ]],\n",
       "\n",
       "       [[0.0481, 0.    , 0.    ],\n",
       "        [0.1047, 0.    , 0.    ],\n",
       "        [0.0679, 0.0085, 0.    ],\n",
       "        [0.0283, 0.    , 0.    ],\n",
       "        [0.0552, 0.0849, 0.    ],\n",
       "        [0.553 , 0.0099, 0.    ],\n",
       "        [0.6167, 0.4272, 0.8883],\n",
       "        [0.4583, 0.8897, 0.0198],\n",
       "        [0.9943, 0.0198, 0.    ],\n",
       "        [0.0651, 0.0438, 0.0057]],\n",
       "\n",
       "       [[0.1047, 0.    , 0.    ],\n",
       "        [0.0679, 0.0085, 0.    ],\n",
       "        [0.0283, 0.    , 0.    ],\n",
       "        [0.0552, 0.0849, 0.    ],\n",
       "        [0.553 , 0.0099, 0.    ],\n",
       "        [0.6167, 0.4272, 0.8883],\n",
       "        [0.4583, 0.8897, 0.0198],\n",
       "        [0.9943, 0.0198, 0.    ],\n",
       "        [0.0651, 0.0438, 0.0057],\n",
       "        [0.1895, 0.0057, 0.    ]],\n",
       "\n",
       "       [[0.0679, 0.0085, 0.    ],\n",
       "        [0.0283, 0.    , 0.    ],\n",
       "        [0.0552, 0.0849, 0.    ],\n",
       "        [0.553 , 0.0099, 0.    ],\n",
       "        [0.6167, 0.4272, 0.8883],\n",
       "        [0.4583, 0.8897, 0.0198],\n",
       "        [0.9943, 0.0198, 0.    ],\n",
       "        [0.0651, 0.0438, 0.0057],\n",
       "        [0.1895, 0.0057, 0.    ],\n",
       "        [0.1386, 0.0071, 0.    ]],\n",
       "\n",
       "       [[0.0283, 0.    , 0.    ],\n",
       "        [0.0552, 0.0849, 0.    ],\n",
       "        [0.553 , 0.0099, 0.    ],\n",
       "        [0.6167, 0.4272, 0.8883],\n",
       "        [0.4583, 0.8897, 0.0198],\n",
       "        [0.9943, 0.0198, 0.    ],\n",
       "        [0.0651, 0.0438, 0.0057],\n",
       "        [0.1895, 0.0057, 0.    ],\n",
       "        [0.1386, 0.0071, 0.    ],\n",
       "        [0.5163, 0.0028, 0.    ]],\n",
       "\n",
       "       [[0.0552, 0.0849, 0.    ],\n",
       "        [0.553 , 0.0099, 0.    ],\n",
       "        [0.6167, 0.4272, 0.8883],\n",
       "        [0.4583, 0.8897, 0.0198],\n",
       "        [0.9943, 0.0198, 0.    ],\n",
       "        [0.0651, 0.0438, 0.0057],\n",
       "        [0.1895, 0.0057, 0.    ],\n",
       "        [0.1386, 0.0071, 0.    ],\n",
       "        [0.5163, 0.0028, 0.    ],\n",
       "        [0.0976, 0.0877, 0.0057]],\n",
       "\n",
       "       [[0.553 , 0.0099, 0.    ],\n",
       "        [0.6167, 0.4272, 0.8883],\n",
       "        [0.4583, 0.8897, 0.0198],\n",
       "        [0.9943, 0.0198, 0.    ],\n",
       "        [0.0651, 0.0438, 0.0057],\n",
       "        [0.1895, 0.0057, 0.    ],\n",
       "        [0.1386, 0.0071, 0.    ],\n",
       "        [0.5163, 0.0028, 0.    ],\n",
       "        [0.0976, 0.0877, 0.0057],\n",
       "        [0.4866, 0.3211, 0.0453]],\n",
       "\n",
       "       [[0.6167, 0.4272, 0.8883],\n",
       "        [0.4583, 0.8897, 0.0198],\n",
       "        [0.9943, 0.0198, 0.    ],\n",
       "        [0.0651, 0.0438, 0.0057],\n",
       "        [0.1895, 0.0057, 0.    ],\n",
       "        [0.1386, 0.0071, 0.    ],\n",
       "        [0.5163, 0.0028, 0.    ],\n",
       "        [0.0976, 0.0877, 0.0057],\n",
       "        [0.4866, 0.3211, 0.0453],\n",
       "        [0.4668, 0.0693, 0.0226]],\n",
       "\n",
       "       [[0.4583, 0.8897, 0.0198],\n",
       "        [0.9943, 0.0198, 0.    ],\n",
       "        [0.0651, 0.0438, 0.0057],\n",
       "        [0.1895, 0.0057, 0.    ],\n",
       "        [0.1386, 0.0071, 0.    ],\n",
       "        [0.5163, 0.0028, 0.    ],\n",
       "        [0.0976, 0.0877, 0.0057],\n",
       "        [0.4866, 0.3211, 0.0453],\n",
       "        [0.4668, 0.0693, 0.0226],\n",
       "        [0.2956, 0.0495, 0.0354]],\n",
       "\n",
       "       [[0.9943, 0.0198, 0.    ],\n",
       "        [0.0651, 0.0438, 0.0057],\n",
       "        [0.1895, 0.0057, 0.    ],\n",
       "        [0.1386, 0.0071, 0.    ],\n",
       "        [0.5163, 0.0028, 0.    ],\n",
       "        [0.0976, 0.0877, 0.0057],\n",
       "        [0.4866, 0.3211, 0.0453],\n",
       "        [0.4668, 0.0693, 0.0226],\n",
       "        [0.2956, 0.0495, 0.0354],\n",
       "        [0.1117, 0.0354, 0.    ]],\n",
       "\n",
       "       [[0.0651, 0.0438, 0.0057],\n",
       "        [0.1895, 0.0057, 0.    ],\n",
       "        [0.1386, 0.0071, 0.    ],\n",
       "        [0.5163, 0.0028, 0.    ],\n",
       "        [0.0976, 0.0877, 0.0057],\n",
       "        [0.4866, 0.3211, 0.0453],\n",
       "        [0.4668, 0.0693, 0.0226],\n",
       "        [0.2956, 0.0495, 0.0354],\n",
       "        [0.1117, 0.0354, 0.    ],\n",
       "        [0.1033, 0.    , 0.0057]],\n",
       "\n",
       "       [[0.1895, 0.0057, 0.    ],\n",
       "        [0.1386, 0.0071, 0.    ],\n",
       "        [0.5163, 0.0028, 0.    ],\n",
       "        [0.0976, 0.0877, 0.0057],\n",
       "        [0.4866, 0.3211, 0.0453],\n",
       "        [0.4668, 0.0693, 0.0226],\n",
       "        [0.2956, 0.0495, 0.0354],\n",
       "        [0.1117, 0.0354, 0.    ],\n",
       "        [0.1033, 0.    , 0.0057],\n",
       "        [0.0608, 0.0226, 0.    ]],\n",
       "\n",
       "       [[0.1386, 0.0071, 0.    ],\n",
       "        [0.5163, 0.0028, 0.    ],\n",
       "        [0.0976, 0.0877, 0.0057],\n",
       "        [0.4866, 0.3211, 0.0453],\n",
       "        [0.4668, 0.0693, 0.0226],\n",
       "        [0.2956, 0.0495, 0.0354],\n",
       "        [0.1117, 0.0354, 0.    ],\n",
       "        [0.1033, 0.    , 0.0057],\n",
       "        [0.0608, 0.0226, 0.    ],\n",
       "        [0.0919, 0.0028, 0.    ]],\n",
       "\n",
       "       [[0.5163, 0.0028, 0.    ],\n",
       "        [0.0976, 0.0877, 0.0057],\n",
       "        [0.4866, 0.3211, 0.0453],\n",
       "        [0.4668, 0.0693, 0.0226],\n",
       "        [0.2956, 0.0495, 0.0354],\n",
       "        [0.1117, 0.0354, 0.    ],\n",
       "        [0.1033, 0.    , 0.0057],\n",
       "        [0.0608, 0.0226, 0.    ],\n",
       "        [0.0919, 0.0028, 0.    ],\n",
       "        [0.0226, 0.    , 0.    ]],\n",
       "\n",
       "       [[0.0976, 0.0877, 0.0057],\n",
       "        [0.4866, 0.3211, 0.0453],\n",
       "        [0.4668, 0.0693, 0.0226],\n",
       "        [0.2956, 0.0495, 0.0354],\n",
       "        [0.1117, 0.0354, 0.    ],\n",
       "        [0.1033, 0.    , 0.0057],\n",
       "        [0.0608, 0.0226, 0.    ],\n",
       "        [0.0919, 0.0028, 0.    ],\n",
       "        [0.0226, 0.    , 0.    ],\n",
       "        [0.0226, 0.0141, 0.0255]],\n",
       "\n",
       "       [[0.4866, 0.3211, 0.0453],\n",
       "        [0.4668, 0.0693, 0.0226],\n",
       "        [0.2956, 0.0495, 0.0354],\n",
       "        [0.1117, 0.0354, 0.    ],\n",
       "        [0.1033, 0.    , 0.0057],\n",
       "        [0.0608, 0.0226, 0.    ],\n",
       "        [0.0919, 0.0028, 0.    ],\n",
       "        [0.0226, 0.    , 0.    ],\n",
       "        [0.0226, 0.0141, 0.0255],\n",
       "        [0.0325, 0.0255, 0.    ]],\n",
       "\n",
       "       [[0.4668, 0.0693, 0.0226],\n",
       "        [0.2956, 0.0495, 0.0354],\n",
       "        [0.1117, 0.0354, 0.    ],\n",
       "        [0.1033, 0.    , 0.0057],\n",
       "        [0.0608, 0.0226, 0.    ],\n",
       "        [0.0919, 0.0028, 0.    ],\n",
       "        [0.0226, 0.    , 0.    ],\n",
       "        [0.0226, 0.0141, 0.0255],\n",
       "        [0.0325, 0.0255, 0.    ],\n",
       "        [0.0962, 0.    , 0.    ]],\n",
       "\n",
       "       [[0.2956, 0.0495, 0.0354],\n",
       "        [0.1117, 0.0354, 0.    ],\n",
       "        [0.1033, 0.    , 0.0057],\n",
       "        [0.0608, 0.0226, 0.    ],\n",
       "        [0.0919, 0.0028, 0.    ],\n",
       "        [0.0226, 0.    , 0.    ],\n",
       "        [0.0226, 0.0141, 0.0255],\n",
       "        [0.0325, 0.0255, 0.    ],\n",
       "        [0.0962, 0.    , 0.    ],\n",
       "        [0.058 , 0.    , 0.    ]],\n",
       "\n",
       "       [[0.1117, 0.0354, 0.    ],\n",
       "        [0.1033, 0.    , 0.0057],\n",
       "        [0.0608, 0.0226, 0.    ],\n",
       "        [0.0919, 0.0028, 0.    ],\n",
       "        [0.0226, 0.    , 0.    ],\n",
       "        [0.0226, 0.0141, 0.0255],\n",
       "        [0.0325, 0.0255, 0.    ],\n",
       "        [0.0962, 0.    , 0.    ],\n",
       "        [0.058 , 0.    , 0.    ],\n",
       "        [0.0523, 0.041 , 0.    ]],\n",
       "\n",
       "       [[0.1033, 0.    , 0.0057],\n",
       "        [0.0608, 0.0226, 0.    ],\n",
       "        [0.0919, 0.0028, 0.    ],\n",
       "        [0.0226, 0.    , 0.    ],\n",
       "        [0.0226, 0.0141, 0.0255],\n",
       "        [0.0325, 0.0255, 0.    ],\n",
       "        [0.0962, 0.    , 0.    ],\n",
       "        [0.058 , 0.    , 0.    ],\n",
       "        [0.0523, 0.041 , 0.    ],\n",
       "        [0.1146, 0.    , 0.0113]],\n",
       "\n",
       "       [[0.0608, 0.0226, 0.    ],\n",
       "        [0.0919, 0.0028, 0.    ],\n",
       "        [0.0226, 0.    , 0.    ],\n",
       "        [0.0226, 0.0141, 0.0255],\n",
       "        [0.0325, 0.0255, 0.    ],\n",
       "        [0.0962, 0.    , 0.    ],\n",
       "        [0.058 , 0.    , 0.    ],\n",
       "        [0.0523, 0.041 , 0.    ],\n",
       "        [0.1146, 0.    , 0.0113],\n",
       "        [0.0948, 0.0226, 0.    ]],\n",
       "\n",
       "       [[0.0919, 0.0028, 0.    ],\n",
       "        [0.0226, 0.    , 0.    ],\n",
       "        [0.0226, 0.0141, 0.0255],\n",
       "        [0.0325, 0.0255, 0.    ],\n",
       "        [0.0962, 0.    , 0.    ],\n",
       "        [0.058 , 0.    , 0.    ],\n",
       "        [0.0523, 0.041 , 0.    ],\n",
       "        [0.1146, 0.    , 0.0113],\n",
       "        [0.0948, 0.0226, 0.    ],\n",
       "        [0.3805, 0.    , 0.0113]],\n",
       "\n",
       "       [[0.0226, 0.    , 0.    ],\n",
       "        [0.0226, 0.0141, 0.0255],\n",
       "        [0.0325, 0.0255, 0.    ],\n",
       "        [0.0962, 0.    , 0.    ],\n",
       "        [0.058 , 0.    , 0.    ],\n",
       "        [0.0523, 0.041 , 0.    ],\n",
       "        [0.1146, 0.    , 0.0113],\n",
       "        [0.0948, 0.0226, 0.    ],\n",
       "        [0.3805, 0.    , 0.0113],\n",
       "        [0.2744, 0.0226, 0.    ]],\n",
       "\n",
       "       [[0.0226, 0.0141, 0.0255],\n",
       "        [0.0325, 0.0255, 0.    ],\n",
       "        [0.0962, 0.    , 0.    ],\n",
       "        [0.058 , 0.    , 0.    ],\n",
       "        [0.0523, 0.041 , 0.    ],\n",
       "        [0.1146, 0.    , 0.0113],\n",
       "        [0.0948, 0.0226, 0.    ],\n",
       "        [0.3805, 0.    , 0.0113],\n",
       "        [0.2744, 0.0226, 0.    ],\n",
       "        [0.1174, 0.0057, 0.    ]],\n",
       "\n",
       "       [[0.0325, 0.0255, 0.    ],\n",
       "        [0.0962, 0.    , 0.    ],\n",
       "        [0.058 , 0.    , 0.    ],\n",
       "        [0.0523, 0.041 , 0.    ],\n",
       "        [0.1146, 0.    , 0.0113],\n",
       "        [0.0948, 0.0226, 0.    ],\n",
       "        [0.3805, 0.    , 0.0113],\n",
       "        [0.2744, 0.0226, 0.    ],\n",
       "        [0.1174, 0.0057, 0.    ],\n",
       "        [0.0693, 0.0198, 0.    ]],\n",
       "\n",
       "       [[0.0962, 0.    , 0.    ],\n",
       "        [0.058 , 0.    , 0.    ],\n",
       "        [0.0523, 0.041 , 0.    ],\n",
       "        [0.1146, 0.    , 0.0113],\n",
       "        [0.0948, 0.0226, 0.    ],\n",
       "        [0.3805, 0.    , 0.0113],\n",
       "        [0.2744, 0.0226, 0.    ],\n",
       "        [0.1174, 0.0057, 0.    ],\n",
       "        [0.0693, 0.0198, 0.    ],\n",
       "        [0.314 , 0.0028, 0.    ]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = Sequential()\n",
    "regressor.add(LSTM(units = 30,input_shape = (10,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.add(Dense(units = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.compile(optimizer = 'sgd',loss = 'mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "30/30 [==============================] - 1s 40ms/step - loss: 0.0578\n",
      "Epoch 2/100\n",
      "30/30 [==============================] - 0s 233us/step - loss: 0.0578\n",
      "Epoch 3/100\n",
      "30/30 [==============================] - 0s 598us/step - loss: 0.0578\n",
      "Epoch 4/100\n",
      "30/30 [==============================] - 0s 499us/step - loss: 0.0578\n",
      "Epoch 5/100\n",
      "30/30 [==============================] - 0s 465us/step - loss: 0.0578\n",
      "Epoch 6/100\n",
      "30/30 [==============================] - 0s 731us/step - loss: 0.0578\n",
      "Epoch 7/100\n",
      "30/30 [==============================] - 0s 432us/step - loss: 0.0578\n",
      "Epoch 8/100\n",
      "30/30 [==============================] - 0s 399us/step - loss: 0.0578\n",
      "Epoch 9/100\n",
      "30/30 [==============================] - 0s 266us/step - loss: 0.0578\n",
      "Epoch 10/100\n",
      "30/30 [==============================] - 0s 366us/step - loss: 0.0578\n",
      "Epoch 11/100\n",
      "30/30 [==============================] - 0s 399us/step - loss: 0.0578\n",
      "Epoch 12/100\n",
      "30/30 [==============================] - 0s 798us/step - loss: 0.0577\n",
      "Epoch 13/100\n",
      "30/30 [==============================] - 0s 332us/step - loss: 0.0577\n",
      "Epoch 14/100\n",
      "30/30 [==============================] - 0s 332us/step - loss: 0.0577\n",
      "Epoch 15/100\n",
      "30/30 [==============================] - 0s 366us/step - loss: 0.0577\n",
      "Epoch 16/100\n",
      "30/30 [==============================] - 0s 366us/step - loss: 0.0577\n",
      "Epoch 17/100\n",
      "30/30 [==============================] - 0s 997us/step - loss: 0.0577\n",
      "Epoch 18/100\n",
      "30/30 [==============================] - 0s 897us/step - loss: 0.0577\n",
      "Epoch 19/100\n",
      "30/30 [==============================] - 0s 798us/step - loss: 0.0577\n",
      "Epoch 20/100\n",
      "30/30 [==============================] - 0s 798us/step - loss: 0.0577\n",
      "Epoch 21/100\n",
      "30/30 [==============================] - 0s 532us/step - loss: 0.0577\n",
      "Epoch 22/100\n",
      "30/30 [==============================] - 0s 499us/step - loss: 0.0577\n",
      "Epoch 23/100\n",
      "30/30 [==============================] - 0s 698us/step - loss: 0.0577\n",
      "Epoch 24/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.0577\n",
      "Epoch 25/100\n",
      "30/30 [==============================] - 0s 465us/step - loss: 0.0577\n",
      "Epoch 26/100\n",
      "30/30 [==============================] - 0s 332us/step - loss: 0.0577\n",
      "Epoch 27/100\n",
      "30/30 [==============================] - 0s 465us/step - loss: 0.0577\n",
      "Epoch 28/100\n",
      "30/30 [==============================] - 0s 366us/step - loss: 0.0577\n",
      "Epoch 29/100\n",
      "30/30 [==============================] - 0s 332us/step - loss: 0.0577\n",
      "Epoch 30/100\n",
      "30/30 [==============================] - 0s 779us/step - loss: 0.0577\n",
      "Epoch 31/100\n",
      "30/30 [==============================] - 0s 485us/step - loss: 0.0577\n",
      "Epoch 32/100\n",
      "30/30 [==============================] - 0s 357us/step - loss: 0.0577\n",
      "Epoch 33/100\n",
      "30/30 [==============================] - 0s 432us/step - loss: 0.0577\n",
      "Epoch 34/100\n",
      "30/30 [==============================] - 0s 565us/step - loss: 0.0577\n",
      "Epoch 35/100\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.0577\n",
      "Epoch 36/100\n",
      "30/30 [==============================] - 0s 502us/step - loss: 0.0577\n",
      "Epoch 37/100\n",
      "30/30 [==============================] - 0s 366us/step - loss: 0.0577\n",
      "Epoch 38/100\n",
      "30/30 [==============================] - 0s 466us/step - loss: 0.0577\n",
      "Epoch 39/100\n",
      "30/30 [==============================] - 0s 499us/step - loss: 0.0577\n",
      "Epoch 40/100\n",
      "30/30 [==============================] - 0s 665us/step - loss: 0.0577\n",
      "Epoch 41/100\n",
      "30/30 [==============================] - 0s 532us/step - loss: 0.0577\n",
      "Epoch 42/100\n",
      "30/30 [==============================] - 0s 532us/step - loss: 0.0577\n",
      "Epoch 43/100\n",
      "30/30 [==============================] - 0s 465us/step - loss: 0.0577\n",
      "Epoch 44/100\n",
      "30/30 [==============================] - 0s 333us/step - loss: 0.0577\n",
      "Epoch 45/100\n",
      "30/30 [==============================] - 0s 465us/step - loss: 0.0577\n",
      "Epoch 46/100\n",
      "30/30 [==============================] - 0s 366us/step - loss: 0.0577\n",
      "Epoch 47/100\n",
      "30/30 [==============================] - 0s 399us/step - loss: 0.0577\n",
      "Epoch 48/100\n",
      "30/30 [==============================] - 0s 332us/step - loss: 0.0577\n",
      "Epoch 49/100\n",
      "30/30 [==============================] - 0s 432us/step - loss: 0.0577\n",
      "Epoch 50/100\n",
      "30/30 [==============================] - 0s 465us/step - loss: 0.0577\n",
      "Epoch 51/100\n",
      "30/30 [==============================] - 0s 532us/step - loss: 0.0577\n",
      "Epoch 52/100\n",
      "30/30 [==============================] - 0s 498us/step - loss: 0.0577\n",
      "Epoch 53/100\n",
      "30/30 [==============================] - 0s 698us/step - loss: 0.0577\n",
      "Epoch 54/100\n",
      "30/30 [==============================] - 0s 332us/step - loss: 0.0577\n",
      "Epoch 55/100\n",
      "30/30 [==============================] - 0s 366us/step - loss: 0.0577\n",
      "Epoch 56/100\n",
      "30/30 [==============================] - 0s 399us/step - loss: 0.0577\n",
      "Epoch 57/100\n",
      "30/30 [==============================] - 0s 366us/step - loss: 0.0577\n",
      "Epoch 58/100\n",
      "30/30 [==============================] - 0s 333us/step - loss: 0.0577\n",
      "Epoch 59/100\n",
      "30/30 [==============================] - 0s 765us/step - loss: 0.0577\n",
      "Epoch 60/100\n",
      "30/30 [==============================] - 0s 365us/step - loss: 0.0577\n",
      "Epoch 61/100\n",
      "30/30 [==============================] - 0s 366us/step - loss: 0.0577\n",
      "Epoch 62/100\n",
      "30/30 [==============================] - 0s 299us/step - loss: 0.0577\n",
      "Epoch 63/100\n",
      "30/30 [==============================] - 0s 399us/step - loss: 0.0577\n",
      "Epoch 64/100\n",
      "30/30 [==============================] - 0s 532us/step - loss: 0.0577\n",
      "Epoch 65/100\n",
      "30/30 [==============================] - 0s 366us/step - loss: 0.0577\n",
      "Epoch 66/100\n",
      "30/30 [==============================] - 0s 266us/step - loss: 0.0577\n",
      "Epoch 67/100\n",
      "30/30 [==============================] - 0s 399us/step - loss: 0.0577\n",
      "Epoch 68/100\n",
      "30/30 [==============================] - 0s 266us/step - loss: 0.0577\n",
      "Epoch 69/100\n",
      "30/30 [==============================] - 0s 366us/step - loss: 0.0577\n",
      "Epoch 70/100\n",
      "30/30 [==============================] - 0s 332us/step - loss: 0.0577\n",
      "Epoch 71/100\n",
      "30/30 [==============================] - 0s 399us/step - loss: 0.0577\n",
      "Epoch 72/100\n",
      "30/30 [==============================] - 0s 332us/step - loss: 0.0577\n",
      "Epoch 73/100\n",
      "30/30 [==============================] - 0s 532us/step - loss: 0.0577\n",
      "Epoch 74/100\n",
      "30/30 [==============================] - 0s 333us/step - loss: 0.0577\n",
      "Epoch 75/100\n",
      "30/30 [==============================] - 0s 366us/step - loss: 0.0577\n",
      "Epoch 76/100\n",
      "30/30 [==============================] - 0s 299us/step - loss: 0.0577\n",
      "Epoch 77/100\n",
      "30/30 [==============================] - 0s 366us/step - loss: 0.0577\n",
      "Epoch 78/100\n",
      "30/30 [==============================] - 0s 432us/step - loss: 0.0577\n",
      "Epoch 79/100\n",
      "30/30 [==============================] - 0s 266us/step - loss: 0.0577\n",
      "Epoch 80/100\n",
      "30/30 [==============================] - 0s 299us/step - loss: 0.0577\n",
      "Epoch 81/100\n",
      "30/30 [==============================] - 0s 366us/step - loss: 0.0577\n",
      "Epoch 82/100\n",
      "30/30 [==============================] - 0s 299us/step - loss: 0.0577\n",
      "Epoch 83/100\n",
      "30/30 [==============================] - 0s 332us/step - loss: 0.0577\n",
      "Epoch 84/100\n",
      "30/30 [==============================] - 0s 299us/step - loss: 0.0577\n",
      "Epoch 85/100\n",
      "30/30 [==============================] - 0s 267us/step - loss: 0.0577\n",
      "Epoch 86/100\n",
      "30/30 [==============================] - 0s 300us/step - loss: 0.0577\n",
      "Epoch 87/100\n",
      "30/30 [==============================] - 0s 333us/step - loss: 0.0577\n",
      "Epoch 88/100\n",
      "30/30 [==============================] - 0s 366us/step - loss: 0.0577\n",
      "Epoch 89/100\n",
      "30/30 [==============================] - 0s 233us/step - loss: 0.0577\n",
      "Epoch 90/100\n",
      "30/30 [==============================] - 0s 366us/step - loss: 0.0577\n",
      "Epoch 91/100\n",
      "30/30 [==============================] - 0s 299us/step - loss: 0.0577\n",
      "Epoch 92/100\n",
      "30/30 [==============================] - 0s 299us/step - loss: 0.0577\n",
      "Epoch 93/100\n",
      "30/30 [==============================] - 0s 299us/step - loss: 0.0577\n",
      "Epoch 94/100\n",
      "30/30 [==============================] - 0s 332us/step - loss: 0.0577\n",
      "Epoch 95/100\n",
      "30/30 [==============================] - 0s 365us/step - loss: 0.0577\n",
      "Epoch 96/100\n",
      "30/30 [==============================] - 0s 432us/step - loss: 0.0577\n",
      "Epoch 97/100\n",
      "30/30 [==============================] - 0s 399us/step - loss: 0.0577\n",
      "Epoch 98/100\n",
      "30/30 [==============================] - 0s 332us/step - loss: 0.0577\n",
      "Epoch 99/100\n",
      "30/30 [==============================] - 0s 333us/step - loss: 0.0577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "30/30 [==============================] - 0s 299us/step - loss: 0.0577\n"
     ]
    }
   ],
   "source": [
    "history=regressor.fit(x_train,y_train,epochs = 100, batch_size = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test= []\n",
    "y_test = []\n",
    "for i in range(40,44):\n",
    "    x_test.append(X[i-10:i, :3])\n",
    "    y_test.append(y[i,:])\n",
    "x_test,y_test = np.array(x_test),np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2842586 , 0.27302152, 0.28019658, 0.2564308 ],\n",
       "       [0.2858243 , 0.27367812, 0.27260795, 0.25812292],\n",
       "       [0.28705525, 0.2771964 , 0.27999204, 0.25814742],\n",
       "       [0.29508978, 0.28092152, 0.285787  , 0.2615378 ]], dtype=float32)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = regressor.predict(x_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1386, 0.3607, 0.2405, 0.4851],\n",
       "       [0.3607, 0.2405, 0.4851, 0.0948],\n",
       "       [0.2405, 0.4851, 0.0948, 0.174 ],\n",
       "       [0.4851, 0.0948, 0.174 , 0.1174]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.48758419, 0.75692132, 0.85832597, 0.52861432],\n",
       "       [0.79241558, 0.87876954, 0.56196238, 0.36726688],\n",
       "       [0.8378178 , 0.57142117, 0.33858105, 0.67403347],\n",
       "       [0.60830711, 0.3374608 , 0.60884508, 0.44888351]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc= []\n",
    "for i in range(0,4):\n",
    "    for index, value in enumerate(y_pred[i]): \n",
    "      acc.append(min(y_test[i][index], y_pred[i][index])/max(y_test[i][index], y_pred[i][index]))\n",
    "i=i+1\n",
    "acc=np.array(acc)\n",
    "acc.reshape(4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
